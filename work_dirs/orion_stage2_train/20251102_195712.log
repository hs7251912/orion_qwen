2025-11-02 19:57:12,828 - mmdet - INFO - Environment info:
------------------------------------------------------------
MMCV: 0.0.1
------------------------------------------------------------

2025-11-02 19:57:15,454 - mmdet - INFO - Distributed training: False
2025-11-02 19:57:17,870 - mmdet - INFO - Config:
point_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]
class_names = [
    'car', 'van', 'truck', 'bicycle', 'traffic_sign', 'traffic_cone',
    'traffic_light', 'pedestrian', 'others'
]
dataset_type = 'B2DOrionDataset'
data_root = '/root/autodl-tmp/Orion_modify/data/bench2drive'
input_modality = dict(
    use_lidar=False,
    use_camera=True,
    use_radar=False,
    use_map=False,
    use_external=True)
file_client_args = dict(backend='disk')
train_pipeline = [
    dict(type='LoadMultiViewImageFromFilesInCeph', to_float32=True),
    dict(type='PhotoMetricDistortionMultiViewImage'),
    dict(
        type='LoadAnnotations3D',
        with_bbox_3d=True,
        with_label_3d=True,
        with_attr_label=True,
        with_light_state=True),
    dict(
        type='VADObjectRangeFilter',
        point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]),
    dict(
        type='VADObjectNameFilter',
        classes=[
            'car', 'van', 'truck', 'bicycle', 'traffic_sign', 'traffic_cone',
            'traffic_light', 'pedestrian', 'others'
        ]),
    dict(
        type='LoadAnnoatationVQA',
        base_desc_path=None,
        tokenizer='/root/autodl-tmp/Orion_modify/ckpts/pretrain_qformer/',
        max_length=2048,
        use_gen_token=True,
        planning_qa_only=True,
        planning_qa_last=True),
    dict(
        type='ResizeCropFlipRotImage',
        data_aug_conf=dict(
            resize_lim=(0.37, 0.45),
            final_dim=(320, 640),
            bot_pct_lim=(0.0, 0.0),
            rot_lim=(0.0, 0.0),
            H=900,
            W=1600,
            rand_flip=False),
        training=True),
    dict(
        type='ResizeMultiview3D',
        img_scale=(640, 640),
        keep_ratio=False,
        multiscale_mode='value'),
    dict(type='PadMultiViewImage', size_divisor=32),
    dict(
        type='NormalizeMultiviewImage',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(
        type='PETRFormatBundle3D',
        class_names=[
            'car', 'van', 'truck', 'bicycle', 'traffic_sign', 'traffic_cone',
            'traffic_light', 'pedestrian', 'others'
        ],
        collect_keys=[
            'lidar2img', 'cam_intrinsic', 'timestamp', 'ego_pose',
            'ego_pose_inv', 'command'
        ]),
    dict(
        type='CustomCollect3D',
        keys=[
            'gt_bboxes_3d', 'gt_labels_3d', 'img', 'ego_his_trajs',
            'input_ids', 'gt_attr_labels', 'ego_fut_trajs', 'ego_fut_masks',
            'ego_fut_cmd', 'ego_lcf_feat', 'vlm_labels', 'can_bus',
            'traffic_state_mask', 'traffic_state', 'lidar2img',
            'cam_intrinsic', 'timestamp', 'ego_pose', 'ego_pose_inv', 'command'
        ])
]
test_pipeline = [
    dict(type='LoadMultiViewImageFromFilesInCeph', to_float32=True),
    dict(
        type='LoadAnnotations3D',
        with_bbox_3d=True,
        with_label_3d=True,
        with_attr_label=True),
    dict(
        type='VADObjectRangeFilter',
        point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]),
    dict(
        type='VADObjectNameFilter',
        classes=[
            'car', 'van', 'truck', 'bicycle', 'traffic_sign', 'traffic_cone',
            'traffic_light', 'pedestrian', 'others'
        ]),
    dict(
        type='ResizeCropFlipRotImage',
        data_aug_conf=dict(
            resize_lim=(0.37, 0.45),
            final_dim=(320, 640),
            bot_pct_lim=(0.0, 0.0),
            rot_lim=(0.0, 0.0),
            H=900,
            W=1600,
            rand_flip=False),
        training=False),
    dict(
        type='ResizeMultiview3D',
        img_scale=(640, 640),
        keep_ratio=False,
        multiscale_mode='value'),
    dict(
        type='NormalizeMultiviewImage',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='PadMultiViewImage', size_divisor=32),
    dict(
        type='LoadAnnoatationCriticalVQATest',
        load_type=['critical_qa'],
        tokenizer='/root/autodl-tmp/Orion_modify/ckpts/pretrain_qformer/',
        use_gen_token=True,
        max_length=2048),
    dict(
        type='MultiScaleFlipAug3D',
        img_scale=(1333, 800),
        pts_scale_ratio=1,
        flip=False,
        transforms=[
            dict(
                type='PETRFormatBundle3D',
                collect_keys=[
                    'lidar2img', 'cam_intrinsic', 'timestamp', 'ego_pose',
                    'ego_pose_inv', 'command'
                ],
                class_names=[
                    'car', 'van', 'truck', 'bicycle', 'traffic_sign',
                    'traffic_cone', 'traffic_light', 'pedestrian', 'others'
                ],
                with_label=False),
            dict(
                type='CustomCollect3D',
                keys=[
                    'gt_bboxes_3d', 'gt_labels_3d', 'img', 'ego_his_trajs',
                    'input_ids', 'gt_attr_labels', 'ego_fut_trajs',
                    'ego_fut_masks', 'ego_fut_cmd', 'ego_lcf_feat',
                    'vlm_labels', 'can_bus', 'fut_valid_flag', 'lidar2img',
                    'cam_intrinsic', 'timestamp', 'ego_pose', 'ego_pose_inv',
                    'command'
                ])
        ])
]
eval_pipeline = [
    dict(
        type='LoadPointsFromFile',
        coord_type='LIDAR',
        load_dim=5,
        use_dim=5,
        file_client_args=dict(backend='disk')),
    dict(
        type='LoadPointsFromMultiSweeps',
        sweeps_num=10,
        file_client_args=dict(backend='disk')),
    dict(
        type='DefaultFormatBundle3D',
        class_names=[
            'car', 'truck', 'trailer', 'bus', 'construction_vehicle',
            'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone', 'barrier'
        ],
        with_label=False),
    dict(type='Collect3D', keys=['points'])
]
data = dict(
    samples_per_gpu=1,
    workers_per_gpu=4,
    train=dict(
        type='B2DOrionDataset',
        data_root='/root/autodl-tmp/Orion_modify/data/bench2drive',
        ann_file='/root/autodl-tmp/Orion_modify/data/infos/b2d_infos_train.pkl',
        pipeline=[
            dict(type='LoadMultiViewImageFromFilesInCeph', to_float32=True),
            dict(type='PhotoMetricDistortionMultiViewImage'),
            dict(
                type='LoadAnnotations3D',
                with_bbox_3d=True,
                with_label_3d=True,
                with_attr_label=True,
                with_light_state=True),
            dict(
                type='VADObjectRangeFilter',
                point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]),
            dict(
                type='VADObjectNameFilter',
                classes=[
                    'car', 'van', 'truck', 'bicycle', 'traffic_sign',
                    'traffic_cone', 'traffic_light', 'pedestrian', 'others'
                ]),
            dict(
                type='LoadAnnoatationVQA',
                base_desc_path=None,
                tokenizer=
                '/root/autodl-tmp/Orion_modify/ckpts/pretrain_qformer/',
                max_length=2048,
                use_gen_token=True,
                planning_qa_only=True,
                planning_qa_last=True),
            dict(
                type='ResizeCropFlipRotImage',
                data_aug_conf=dict(
                    resize_lim=(0.37, 0.45),
                    final_dim=(320, 640),
                    bot_pct_lim=(0.0, 0.0),
                    rot_lim=(0.0, 0.0),
                    H=900,
                    W=1600,
                    rand_flip=False),
                training=True),
            dict(
                type='ResizeMultiview3D',
                img_scale=(640, 640),
                keep_ratio=False,
                multiscale_mode='value'),
            dict(type='PadMultiViewImage', size_divisor=32),
            dict(
                type='NormalizeMultiviewImage',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(
                type='PETRFormatBundle3D',
                class_names=[
                    'car', 'van', 'truck', 'bicycle', 'traffic_sign',
                    'traffic_cone', 'traffic_light', 'pedestrian', 'others'
                ],
                collect_keys=[
                    'lidar2img', 'cam_intrinsic', 'timestamp', 'ego_pose',
                    'ego_pose_inv', 'command'
                ]),
            dict(
                type='CustomCollect3D',
                keys=[
                    'gt_bboxes_3d', 'gt_labels_3d', 'img', 'ego_his_trajs',
                    'input_ids', 'gt_attr_labels', 'ego_fut_trajs',
                    'ego_fut_masks', 'ego_fut_cmd', 'ego_lcf_feat',
                    'vlm_labels', 'can_bus', 'traffic_state_mask',
                    'traffic_state', 'lidar2img', 'cam_intrinsic', 'timestamp',
                    'ego_pose', 'ego_pose_inv', 'command'
                ])
        ],
        classes=[
            'car', 'van', 'truck', 'bicycle', 'traffic_sign', 'traffic_cone',
            'traffic_light', 'pedestrian', 'others'
        ],
        modality=dict(
            use_lidar=False,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=True),
        test_mode=False,
        box_type_3d='LiDAR',
        seq_mode=True,
        seq_split_num=1,
        name_mapping=dict({
            'vehicle.bh.crossbike':
            'bicycle',
            'vehicle.diamondback.century':
            'bicycle',
            'vehicle.gazelle.omafiets':
            'bicycle',
            'vehicle.audi.etron':
            'car',
            'vehicle.chevrolet.impala':
            'car',
            'vehicle.dodge.charger_2020':
            'car',
            'vehicle.dodge.charger_police':
            'car',
            'vehicle.dodge.charger_police_2020':
            'car',
            'vehicle.lincoln.mkz_2017':
            'car',
            'vehicle.lincoln.mkz_2020':
            'car',
            'vehicle.mini.cooper_s_2021':
            'car',
            'vehicle.mercedes.coupe_2020':
            'car',
            'vehicle.ford.mustang':
            'car',
            'vehicle.nissan.patrol_2021':
            'car',
            'vehicle.audi.tt':
            'car',
            'vehicle.ford.crown':
            'car',
            'vehicle.tesla.model3':
            'car',
            '/Game/Carla/Static/Car/4Wheeled/ParkedVehicles/FordCrown/SM_FordCrown_parked.SM_FordCrown_parked':
            'car',
            '/Game/Carla/Static/Car/4Wheeled/ParkedVehicles/Charger/SM_ChargerParked.SM_ChargerParked':
            'car',
            '/Game/Carla/Static/Car/4Wheeled/ParkedVehicles/Lincoln/SM_LincolnParked.SM_LincolnParked':
            'car',
            '/Game/Carla/Static/Car/4Wheeled/ParkedVehicles/MercedesCCC/SM_MercedesCCC_Parked.SM_MercedesCCC_Parked':
            'car',
            '/Game/Carla/Static/Car/4Wheeled/ParkedVehicles/Mini2021/SM_Mini2021_parked.SM_Mini2021_parked':
            'car',
            '/Game/Carla/Static/Car/4Wheeled/ParkedVehicles/NissanPatrol2021/SM_NissanPatrol2021_parked.SM_NissanPatrol2021_parked':
            'car',
            '/Game/Carla/Static/Car/4Wheeled/ParkedVehicles/TeslaM3/SM_TeslaM3_parked.SM_TeslaM3_parked':
            'car',
            '/Game/Carla/Static/Car/4Wheeled/ParkedVehicles/VolkswagenT2/SM_VolkswagenT2_2021_Parked.SM_VolkswagenT2_2021_Parked':
            'van',
            'vehicle.ford.ambulance':
            'van',
            'vehicle.carlamotors.firetruck':
            'truck',
            'traffic.speed_limit.30':
            'traffic_sign',
            'traffic.speed_limit.40':
            'traffic_sign',
            'traffic.speed_limit.50':
            'traffic_sign',
            'traffic.speed_limit.60':
            'traffic_sign',
            'traffic.speed_limit.90':
            'traffic_sign',
            'traffic.speed_limit.120':
            'traffic_sign',
            'traffic.stop':
            'traffic_sign',
            'traffic.yield':
            'traffic_sign',
            'traffic.traffic_light':
            'traffic_light',
            'static.prop.warningconstruction':
            'traffic_cone',
            'static.prop.warningaccident':
            'traffic_cone',
            'static.prop.trafficwarning':
            'traffic_cone',
            'static.prop.constructioncone':
            'traffic_cone',
            'walker.pedestrian.0001':
            'pedestrian',
            'walker.pedestrian.0003':
            'pedestrian',
            'walker.pedestrian.0004':
            'pedestrian',
            'walker.pedestrian.0005':
            'pedestrian',
            'walker.pedestrian.0007':
            'pedestrian',
            'walker.pedestrian.0010':
            'pedestrian',
            'walker.pedestrian.0013':
            'pedestrian',
            'walker.pedestrian.0014':
            'pedestrian',
            'walker.pedestrian.0015':
            'pedestrian',
            'walker.pedestrian.0016':
            'pedestrian',
            'walker.pedestrian.0017':
            'pedestrian',
            'walker.pedestrian.0018':
            'pedestrian',
            'walker.pedestrian.0019':
            'pedestrian',
            'walker.pedestrian.0020':
            'pedestrian',
            'walker.pedestrian.0021':
            'pedestrian',
            'walker.pedestrian.0022':
            'pedestrian',
            'walker.pedestrian.0025':
            'pedestrian',
            'walker.pedestrian.0027':
            'pedestrian',
            'walker.pedestrian.0030':
            'pedestrian',
            'walker.pedestrian.0031':
            'pedestrian',
            'walker.pedestrian.0032':
            'pedestrian',
            'walker.pedestrian.0034':
            'pedestrian',
            'walker.pedestrian.0035':
            'pedestrian',
            'walker.pedestrian.0041':
            'pedestrian',
            'walker.pedestrian.0042':
            'pedestrian',
            'walker.pedestrian.0046':
            'pedestrian',
            'walker.pedestrian.0047':
            'pedestrian',
            'static.prop.dirtdebris01':
            'others',
            'static.prop.dirtdebris02':
            'others'
        }),
        map_root='/root/autodl-tmp/Orion_modify/data/bench2drive/maps',
        map_file='/root/autodl-tmp/Orion_modify/data/infos/b2d_map_infos.pkl',
        queue_length=1,
        past_frames=2,
        future_frames=6,
        point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0],
        polyline_points_num=11),
    val=dict(
        type='B2DOrionDataset',
        data_root='/root/autodl-tmp/Orion_modify/data/bench2drive',
        ann_file='/root/autodl-tmp/Orion_modify/data/infos/b2d_infos_val.pkl',
        pipeline=[
            dict(type='LoadMultiViewImageFromFilesInCeph', to_float32=True),
            dict(
                type='LoadAnnotations3D',
                with_bbox_3d=True,
                with_label_3d=True,
                with_attr_label=True),
            dict(
                type='VADObjectRangeFilter',
                point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]),
            dict(
                type='VADObjectNameFilter',
                classes=[
                    'car', 'van', 'truck', 'bicycle', 'traffic_sign',
                    'traffic_cone', 'traffic_light', 'pedestrian', 'others'
                ]),
            dict(
                type='ResizeCropFlipRotImage',
                data_aug_conf=dict(
                    resize_lim=(0.37, 0.45),
                    final_dim=(320, 640),
                    bot_pct_lim=(0.0, 0.0),
                    rot_lim=(0.0, 0.0),
                    H=900,
                    W=1600,
                    rand_flip=False),
                training=False),
            dict(
                type='ResizeMultiview3D',
                img_scale=(640, 640),
                keep_ratio=False,
                multiscale_mode='value'),
            dict(
                type='NormalizeMultiviewImage',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='PadMultiViewImage', size_divisor=32),
            dict(
                type='LoadAnnoatationCriticalVQATest',
                load_type=['critical_qa'],
                tokenizer=
                '/root/autodl-tmp/Orion_modify/ckpts/pretrain_qformer/',
                use_gen_token=True,
                max_length=2048),
            dict(
                type='MultiScaleFlipAug3D',
                img_scale=(1333, 800),
                pts_scale_ratio=1,
                flip=False,
                transforms=[
                    dict(
                        type='PETRFormatBundle3D',
                        collect_keys=[
                            'lidar2img', 'cam_intrinsic', 'timestamp',
                            'ego_pose', 'ego_pose_inv', 'command'
                        ],
                        class_names=[
                            'car', 'van', 'truck', 'bicycle', 'traffic_sign',
                            'traffic_cone', 'traffic_light', 'pedestrian',
                            'others'
                        ],
                        with_label=False),
                    dict(
                        type='CustomCollect3D',
                        keys=[
                            'gt_bboxes_3d', 'gt_labels_3d', 'img',
                            'ego_his_trajs', 'input_ids', 'gt_attr_labels',
                            'ego_fut_trajs', 'ego_fut_masks', 'ego_fut_cmd',
                            'ego_lcf_feat', 'vlm_labels', 'can_bus',
                            'fut_valid_flag', 'lidar2img', 'cam_intrinsic',
                            'timestamp', 'ego_pose', 'ego_pose_inv', 'command'
                        ])
                ])
        ],
        classes=[
            'car', 'van', 'truck', 'bicycle', 'traffic_sign', 'traffic_cone',
            'traffic_light', 'pedestrian', 'others'
        ],
        modality=dict(
            use_lidar=False,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=True),
        test_mode=True,
        box_type_3d='LiDAR',
        name_mapping=dict({
            'vehicle.bh.crossbike':
            'bicycle',
            'vehicle.diamondback.century':
            'bicycle',
            'vehicle.gazelle.omafiets':
            'bicycle',
            'vehicle.audi.etron':
            'car',
            'vehicle.chevrolet.impala':
            'car',
            'vehicle.dodge.charger_2020':
            'car',
            'vehicle.dodge.charger_police':
            'car',
            'vehicle.dodge.charger_police_2020':
            'car',
            'vehicle.lincoln.mkz_2017':
            'car',
            'vehicle.lincoln.mkz_2020':
            'car',
            'vehicle.mini.cooper_s_2021':
            'car',
            'vehicle.mercedes.coupe_2020':
            'car',
            'vehicle.ford.mustang':
            'car',
            'vehicle.nissan.patrol_2021':
            'car',
            'vehicle.audi.tt':
            'car',
            'vehicle.ford.crown':
            'car',
            'vehicle.tesla.model3':
            'car',
            '/Game/Carla/Static/Car/4Wheeled/ParkedVehicles/FordCrown/SM_FordCrown_parked.SM_FordCrown_parked':
            'car',
            '/Game/Carla/Static/Car/4Wheeled/ParkedVehicles/Charger/SM_ChargerParked.SM_ChargerParked':
            'car',
            '/Game/Carla/Static/Car/4Wheeled/ParkedVehicles/Lincoln/SM_LincolnParked.SM_LincolnParked':
            'car',
            '/Game/Carla/Static/Car/4Wheeled/ParkedVehicles/MercedesCCC/SM_MercedesCCC_Parked.SM_MercedesCCC_Parked':
            'car',
            '/Game/Carla/Static/Car/4Wheeled/ParkedVehicles/Mini2021/SM_Mini2021_parked.SM_Mini2021_parked':
            'car',
            '/Game/Carla/Static/Car/4Wheeled/ParkedVehicles/NissanPatrol2021/SM_NissanPatrol2021_parked.SM_NissanPatrol2021_parked':
            'car',
            '/Game/Carla/Static/Car/4Wheeled/ParkedVehicles/TeslaM3/SM_TeslaM3_parked.SM_TeslaM3_parked':
            'car',
            '/Game/Carla/Static/Car/4Wheeled/ParkedVehicles/VolkswagenT2/SM_VolkswagenT2_2021_Parked.SM_VolkswagenT2_2021_Parked':
            'van',
            'vehicle.ford.ambulance':
            'van',
            'vehicle.carlamotors.firetruck':
            'truck',
            'traffic.speed_limit.30':
            'traffic_sign',
            'traffic.speed_limit.40':
            'traffic_sign',
            'traffic.speed_limit.50':
            'traffic_sign',
            'traffic.speed_limit.60':
            'traffic_sign',
            'traffic.speed_limit.90':
            'traffic_sign',
            'traffic.speed_limit.120':
            'traffic_sign',
            'traffic.stop':
            'traffic_sign',
            'traffic.yield':
            'traffic_sign',
            'traffic.traffic_light':
            'traffic_light',
            'static.prop.warningconstruction':
            'traffic_cone',
            'static.prop.warningaccident':
            'traffic_cone',
            'static.prop.trafficwarning':
            'traffic_cone',
            'static.prop.constructioncone':
            'traffic_cone',
            'walker.pedestrian.0001':
            'pedestrian',
            'walker.pedestrian.0003':
            'pedestrian',
            'walker.pedestrian.0004':
            'pedestrian',
            'walker.pedestrian.0005':
            'pedestrian',
            'walker.pedestrian.0007':
            'pedestrian',
            'walker.pedestrian.0010':
            'pedestrian',
            'walker.pedestrian.0013':
            'pedestrian',
            'walker.pedestrian.0014':
            'pedestrian',
            'walker.pedestrian.0015':
            'pedestrian',
            'walker.pedestrian.0016':
            'pedestrian',
            'walker.pedestrian.0017':
            'pedestrian',
            'walker.pedestrian.0018':
            'pedestrian',
            'walker.pedestrian.0019':
            'pedestrian',
            'walker.pedestrian.0020':
            'pedestrian',
            'walker.pedestrian.0021':
            'pedestrian',
            'walker.pedestrian.0022':
            'pedestrian',
            'walker.pedestrian.0025':
            'pedestrian',
            'walker.pedestrian.0027':
            'pedestrian',
            'walker.pedestrian.0030':
            'pedestrian',
            'walker.pedestrian.0031':
            'pedestrian',
            'walker.pedestrian.0032':
            'pedestrian',
            'walker.pedestrian.0034':
            'pedestrian',
            'walker.pedestrian.0035':
            'pedestrian',
            'walker.pedestrian.0041':
            'pedestrian',
            'walker.pedestrian.0042':
            'pedestrian',
            'walker.pedestrian.0046':
            'pedestrian',
            'walker.pedestrian.0047':
            'pedestrian',
            'static.prop.dirtdebris01':
            'others',
            'static.prop.dirtdebris02':
            'others'
        }),
        map_root='/root/autodl-tmp/Orion_modify/data/bench2drive/maps',
        map_file='/root/autodl-tmp/Orion_modify/data/infos/b2d_map_infos.pkl',
        queue_length=1,
        past_frames=2,
        future_frames=6,
        point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0],
        polyline_points_num=11,
        eval_cfg=dict(
            dist_ths=[0.5, 1.0, 2.0, 4.0],
            dist_th_tp=2.0,
            min_recall=0.1,
            min_precision=0.1,
            mean_ap_weight=5,
            class_names=[
                'car', 'van', 'truck', 'bicycle', 'traffic_sign',
                'traffic_cone', 'traffic_light', 'pedestrian'
            ],
            tp_metrics=['trans_err', 'scale_err', 'orient_err', 'vel_err'],
            err_name_maping=dict(
                trans_err='mATE',
                scale_err='mASE',
                orient_err='mAOE',
                vel_err='mAVE',
                attr_err='mAAE'),
            class_range=dict(
                car=(50, 50),
                van=(50, 50),
                truck=(50, 50),
                bicycle=(40, 40),
                traffic_sign=(30, 30),
                traffic_cone=(30, 30),
                traffic_light=(30, 30),
                pedestrian=(40, 40)))),
    test=dict(
        type='B2DOrionDataset',
        data_root='/root/autodl-tmp/Orion_modify/data/bench2drive',
        ann_file='/root/autodl-tmp/Orion_modify/data/infos/b2d_infos_val.pkl',
        pipeline=[
            dict(type='LoadMultiViewImageFromFilesInCeph', to_float32=True),
            dict(
                type='LoadAnnotations3D',
                with_bbox_3d=True,
                with_label_3d=True,
                with_attr_label=True),
            dict(
                type='VADObjectRangeFilter',
                point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]),
            dict(
                type='VADObjectNameFilter',
                classes=[
                    'car', 'van', 'truck', 'bicycle', 'traffic_sign',
                    'traffic_cone', 'traffic_light', 'pedestrian', 'others'
                ]),
            dict(
                type='ResizeCropFlipRotImage',
                data_aug_conf=dict(
                    resize_lim=(0.37, 0.45),
                    final_dim=(320, 640),
                    bot_pct_lim=(0.0, 0.0),
                    rot_lim=(0.0, 0.0),
                    H=900,
                    W=1600,
                    rand_flip=False),
                training=False),
            dict(
                type='ResizeMultiview3D',
                img_scale=(640, 640),
                keep_ratio=False,
                multiscale_mode='value'),
            dict(
                type='NormalizeMultiviewImage',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='PadMultiViewImage', size_divisor=32),
            dict(
                type='LoadAnnoatationCriticalVQATest',
                load_type=['critical_qa'],
                tokenizer=
                '/root/autodl-tmp/Orion_modify/ckpts/pretrain_qformer/',
                use_gen_token=True,
                max_length=2048),
            dict(
                type='MultiScaleFlipAug3D',
                img_scale=(1333, 800),
                pts_scale_ratio=1,
                flip=False,
                transforms=[
                    dict(
                        type='PETRFormatBundle3D',
                        collect_keys=[
                            'lidar2img', 'cam_intrinsic', 'timestamp',
                            'ego_pose', 'ego_pose_inv', 'command'
                        ],
                        class_names=[
                            'car', 'van', 'truck', 'bicycle', 'traffic_sign',
                            'traffic_cone', 'traffic_light', 'pedestrian',
                            'others'
                        ],
                        with_label=False),
                    dict(
                        type='CustomCollect3D',
                        keys=[
                            'gt_bboxes_3d', 'gt_labels_3d', 'img',
                            'ego_his_trajs', 'input_ids', 'gt_attr_labels',
                            'ego_fut_trajs', 'ego_fut_masks', 'ego_fut_cmd',
                            'ego_lcf_feat', 'vlm_labels', 'can_bus',
                            'fut_valid_flag', 'lidar2img', 'cam_intrinsic',
                            'timestamp', 'ego_pose', 'ego_pose_inv', 'command'
                        ])
                ])
        ],
        classes=[
            'car', 'van', 'truck', 'bicycle', 'traffic_sign', 'traffic_cone',
            'traffic_light', 'pedestrian', 'others'
        ],
        modality=dict(
            use_lidar=False,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=True),
        test_mode=True,
        box_type_3d='LiDAR',
        name_mapping=dict({
            'vehicle.bh.crossbike':
            'bicycle',
            'vehicle.diamondback.century':
            'bicycle',
            'vehicle.gazelle.omafiets':
            'bicycle',
            'vehicle.audi.etron':
            'car',
            'vehicle.chevrolet.impala':
            'car',
            'vehicle.dodge.charger_2020':
            'car',
            'vehicle.dodge.charger_police':
            'car',
            'vehicle.dodge.charger_police_2020':
            'car',
            'vehicle.lincoln.mkz_2017':
            'car',
            'vehicle.lincoln.mkz_2020':
            'car',
            'vehicle.mini.cooper_s_2021':
            'car',
            'vehicle.mercedes.coupe_2020':
            'car',
            'vehicle.ford.mustang':
            'car',
            'vehicle.nissan.patrol_2021':
            'car',
            'vehicle.audi.tt':
            'car',
            'vehicle.ford.crown':
            'car',
            'vehicle.tesla.model3':
            'car',
            '/Game/Carla/Static/Car/4Wheeled/ParkedVehicles/FordCrown/SM_FordCrown_parked.SM_FordCrown_parked':
            'car',
            '/Game/Carla/Static/Car/4Wheeled/ParkedVehicles/Charger/SM_ChargerParked.SM_ChargerParked':
            'car',
            '/Game/Carla/Static/Car/4Wheeled/ParkedVehicles/Lincoln/SM_LincolnParked.SM_LincolnParked':
            'car',
            '/Game/Carla/Static/Car/4Wheeled/ParkedVehicles/MercedesCCC/SM_MercedesCCC_Parked.SM_MercedesCCC_Parked':
            'car',
            '/Game/Carla/Static/Car/4Wheeled/ParkedVehicles/Mini2021/SM_Mini2021_parked.SM_Mini2021_parked':
            'car',
            '/Game/Carla/Static/Car/4Wheeled/ParkedVehicles/NissanPatrol2021/SM_NissanPatrol2021_parked.SM_NissanPatrol2021_parked':
            'car',
            '/Game/Carla/Static/Car/4Wheeled/ParkedVehicles/TeslaM3/SM_TeslaM3_parked.SM_TeslaM3_parked':
            'car',
            '/Game/Carla/Static/Car/4Wheeled/ParkedVehicles/VolkswagenT2/SM_VolkswagenT2_2021_Parked.SM_VolkswagenT2_2021_Parked':
            'van',
            'vehicle.ford.ambulance':
            'van',
            'vehicle.carlamotors.firetruck':
            'truck',
            'traffic.speed_limit.30':
            'traffic_sign',
            'traffic.speed_limit.40':
            'traffic_sign',
            'traffic.speed_limit.50':
            'traffic_sign',
            'traffic.speed_limit.60':
            'traffic_sign',
            'traffic.speed_limit.90':
            'traffic_sign',
            'traffic.speed_limit.120':
            'traffic_sign',
            'traffic.stop':
            'traffic_sign',
            'traffic.yield':
            'traffic_sign',
            'traffic.traffic_light':
            'traffic_light',
            'static.prop.warningconstruction':
            'traffic_cone',
            'static.prop.warningaccident':
            'traffic_cone',
            'static.prop.trafficwarning':
            'traffic_cone',
            'static.prop.constructioncone':
            'traffic_cone',
            'walker.pedestrian.0001':
            'pedestrian',
            'walker.pedestrian.0003':
            'pedestrian',
            'walker.pedestrian.0004':
            'pedestrian',
            'walker.pedestrian.0005':
            'pedestrian',
            'walker.pedestrian.0007':
            'pedestrian',
            'walker.pedestrian.0010':
            'pedestrian',
            'walker.pedestrian.0013':
            'pedestrian',
            'walker.pedestrian.0014':
            'pedestrian',
            'walker.pedestrian.0015':
            'pedestrian',
            'walker.pedestrian.0016':
            'pedestrian',
            'walker.pedestrian.0017':
            'pedestrian',
            'walker.pedestrian.0018':
            'pedestrian',
            'walker.pedestrian.0019':
            'pedestrian',
            'walker.pedestrian.0020':
            'pedestrian',
            'walker.pedestrian.0021':
            'pedestrian',
            'walker.pedestrian.0022':
            'pedestrian',
            'walker.pedestrian.0025':
            'pedestrian',
            'walker.pedestrian.0027':
            'pedestrian',
            'walker.pedestrian.0030':
            'pedestrian',
            'walker.pedestrian.0031':
            'pedestrian',
            'walker.pedestrian.0032':
            'pedestrian',
            'walker.pedestrian.0034':
            'pedestrian',
            'walker.pedestrian.0035':
            'pedestrian',
            'walker.pedestrian.0041':
            'pedestrian',
            'walker.pedestrian.0042':
            'pedestrian',
            'walker.pedestrian.0046':
            'pedestrian',
            'walker.pedestrian.0047':
            'pedestrian',
            'static.prop.dirtdebris01':
            'others',
            'static.prop.dirtdebris02':
            'others'
        }),
        map_root='/root/autodl-tmp/Orion_modify/data/bench2drive/maps',
        map_file='/root/autodl-tmp/Orion_modify/data/infos/b2d_map_infos.pkl',
        queue_length=1,
        past_frames=2,
        future_frames=6,
        point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0],
        polyline_points_num=11,
        eval_cfg=dict(
            dist_ths=[0.5, 1.0, 2.0, 4.0],
            dist_th_tp=2.0,
            min_recall=0.1,
            min_precision=0.1,
            mean_ap_weight=5,
            class_names=[
                'car', 'van', 'truck', 'bicycle', 'traffic_sign',
                'traffic_cone', 'traffic_light', 'pedestrian'
            ],
            tp_metrics=['trans_err', 'scale_err', 'orient_err', 'vel_err'],
            err_name_maping=dict(
                trans_err='mATE',
                scale_err='mASE',
                orient_err='mAOE',
                vel_err='mAVE',
                attr_err='mAAE'),
            class_range=dict(
                car=(50, 50),
                van=(50, 50),
                truck=(50, 50),
                bicycle=(40, 40),
                traffic_sign=(30, 30),
                traffic_cone=(30, 30),
                traffic_light=(30, 30),
                pedestrian=(40, 40)))),
    shuffler_sampler=dict(
        type='InfiniteGroupEachSampleInBatchSampler',
        seq_split_num=10,
        warmup_split_num=80,
        num_iters_to_seq=234769),
    nonshuffler_sampler=dict(type='DistributedSampler'))
evaluation = dict(
    interval=1643383,
    pipeline=[
        dict(type='LoadMultiViewImageFromFilesInCeph', to_float32=True),
        dict(
            type='LoadAnnotations3D',
            with_bbox_3d=True,
            with_label_3d=True,
            with_attr_label=True),
        dict(
            type='VADObjectRangeFilter',
            point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]),
        dict(
            type='VADObjectNameFilter',
            classes=[
                'car', 'van', 'truck', 'bicycle', 'traffic_sign',
                'traffic_cone', 'traffic_light', 'pedestrian', 'others'
            ]),
        dict(
            type='ResizeCropFlipRotImage',
            data_aug_conf=dict(
                resize_lim=(0.37, 0.45),
                final_dim=(320, 640),
                bot_pct_lim=(0.0, 0.0),
                rot_lim=(0.0, 0.0),
                H=900,
                W=1600,
                rand_flip=False),
            training=False),
        dict(
            type='ResizeMultiview3D',
            img_scale=(640, 640),
            keep_ratio=False,
            multiscale_mode='value'),
        dict(
            type='NormalizeMultiviewImage',
            mean=[123.675, 116.28, 103.53],
            std=[58.395, 57.12, 57.375],
            to_rgb=True),
        dict(type='PadMultiViewImage', size_divisor=32),
        dict(
            type='LoadAnnoatationCriticalVQATest',
            load_type=['critical_qa'],
            tokenizer='/root/autodl-tmp/Orion_modify/ckpts/pretrain_qformer/',
            use_gen_token=True,
            max_length=2048),
        dict(
            type='MultiScaleFlipAug3D',
            img_scale=(1333, 800),
            pts_scale_ratio=1,
            flip=False,
            transforms=[
                dict(
                    type='PETRFormatBundle3D',
                    collect_keys=[
                        'lidar2img', 'cam_intrinsic', 'timestamp', 'ego_pose',
                        'ego_pose_inv', 'command'
                    ],
                    class_names=[
                        'car', 'van', 'truck', 'bicycle', 'traffic_sign',
                        'traffic_cone', 'traffic_light', 'pedestrian', 'others'
                    ],
                    with_label=False),
                dict(
                    type='CustomCollect3D',
                    keys=[
                        'gt_bboxes_3d', 'gt_labels_3d', 'img', 'ego_his_trajs',
                        'input_ids', 'gt_attr_labels', 'ego_fut_trajs',
                        'ego_fut_masks', 'ego_fut_cmd', 'ego_lcf_feat',
                        'vlm_labels', 'can_bus', 'fut_valid_flag', 'lidar2img',
                        'cam_intrinsic', 'timestamp', 'ego_pose',
                        'ego_pose_inv', 'command'
                    ])
            ])
    ])
checkpoint_config = dict(interval=234769, max_keep_ckpts=3)
log_config = dict(
    interval=10,
    hooks=[dict(type='TextLoggerHook'),
           dict(type='TensorboardLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
work_dir = './work_dirs/orion_stage2_train'
load_from = '/root/autodl-tmp/Orion_modify/ckpts/Orion.pth'
resume_from = None
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
backbone_norm_cfg = dict(type='LN', requires_grad=True)
voxel_size = [0.2, 0.2, 8]
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
map_classes = [
    'Broken', 'Solid', 'SolidSolid', 'Center', 'TrafficLight', 'StopSign'
]
queue_length = 1
map_fixed_ptsnum_per_gt_line = 11
map_eval_use_same_gt_sample_num_flag = True
map_num_classes = 6
past_frames = 2
future_frames = 6
_dim_ = 256
_pos_dim_ = 128
_ffn_dim_ = 512
ida_aug_conf = dict(
    resize_lim=(0.37, 0.45),
    final_dim=(320, 640),
    bot_pct_lim=(0.0, 0.0),
    rot_lim=(0.0, 0.0),
    H=900,
    W=1600,
    rand_flip=False)
occflow_grid_conf = dict(
    xbound=[-50.0, 50.0, 0.5],
    ybound=[-50.0, 50.0, 0.5],
    zbound=[-10.0, 10.0, 20.0])
NameMapping = dict({
    'vehicle.bh.crossbike':
    'bicycle',
    'vehicle.diamondback.century':
    'bicycle',
    'vehicle.gazelle.omafiets':
    'bicycle',
    'vehicle.audi.etron':
    'car',
    'vehicle.chevrolet.impala':
    'car',
    'vehicle.dodge.charger_2020':
    'car',
    'vehicle.dodge.charger_police':
    'car',
    'vehicle.dodge.charger_police_2020':
    'car',
    'vehicle.lincoln.mkz_2017':
    'car',
    'vehicle.lincoln.mkz_2020':
    'car',
    'vehicle.mini.cooper_s_2021':
    'car',
    'vehicle.mercedes.coupe_2020':
    'car',
    'vehicle.ford.mustang':
    'car',
    'vehicle.nissan.patrol_2021':
    'car',
    'vehicle.audi.tt':
    'car',
    'vehicle.ford.crown':
    'car',
    'vehicle.tesla.model3':
    'car',
    '/Game/Carla/Static/Car/4Wheeled/ParkedVehicles/FordCrown/SM_FordCrown_parked.SM_FordCrown_parked':
    'car',
    '/Game/Carla/Static/Car/4Wheeled/ParkedVehicles/Charger/SM_ChargerParked.SM_ChargerParked':
    'car',
    '/Game/Carla/Static/Car/4Wheeled/ParkedVehicles/Lincoln/SM_LincolnParked.SM_LincolnParked':
    'car',
    '/Game/Carla/Static/Car/4Wheeled/ParkedVehicles/MercedesCCC/SM_MercedesCCC_Parked.SM_MercedesCCC_Parked':
    'car',
    '/Game/Carla/Static/Car/4Wheeled/ParkedVehicles/Mini2021/SM_Mini2021_parked.SM_Mini2021_parked':
    'car',
    '/Game/Carla/Static/Car/4Wheeled/ParkedVehicles/NissanPatrol2021/SM_NissanPatrol2021_parked.SM_NissanPatrol2021_parked':
    'car',
    '/Game/Carla/Static/Car/4Wheeled/ParkedVehicles/TeslaM3/SM_TeslaM3_parked.SM_TeslaM3_parked':
    'car',
    '/Game/Carla/Static/Car/4Wheeled/ParkedVehicles/VolkswagenT2/SM_VolkswagenT2_2021_Parked.SM_VolkswagenT2_2021_Parked':
    'van',
    'vehicle.ford.ambulance':
    'van',
    'vehicle.carlamotors.firetruck':
    'truck',
    'traffic.speed_limit.30':
    'traffic_sign',
    'traffic.speed_limit.40':
    'traffic_sign',
    'traffic.speed_limit.50':
    'traffic_sign',
    'traffic.speed_limit.60':
    'traffic_sign',
    'traffic.speed_limit.90':
    'traffic_sign',
    'traffic.speed_limit.120':
    'traffic_sign',
    'traffic.stop':
    'traffic_sign',
    'traffic.yield':
    'traffic_sign',
    'traffic.traffic_light':
    'traffic_light',
    'static.prop.warningconstruction':
    'traffic_cone',
    'static.prop.warningaccident':
    'traffic_cone',
    'static.prop.trafficwarning':
    'traffic_cone',
    'static.prop.constructioncone':
    'traffic_cone',
    'walker.pedestrian.0001':
    'pedestrian',
    'walker.pedestrian.0003':
    'pedestrian',
    'walker.pedestrian.0004':
    'pedestrian',
    'walker.pedestrian.0005':
    'pedestrian',
    'walker.pedestrian.0007':
    'pedestrian',
    'walker.pedestrian.0010':
    'pedestrian',
    'walker.pedestrian.0013':
    'pedestrian',
    'walker.pedestrian.0014':
    'pedestrian',
    'walker.pedestrian.0015':
    'pedestrian',
    'walker.pedestrian.0016':
    'pedestrian',
    'walker.pedestrian.0017':
    'pedestrian',
    'walker.pedestrian.0018':
    'pedestrian',
    'walker.pedestrian.0019':
    'pedestrian',
    'walker.pedestrian.0020':
    'pedestrian',
    'walker.pedestrian.0021':
    'pedestrian',
    'walker.pedestrian.0022':
    'pedestrian',
    'walker.pedestrian.0025':
    'pedestrian',
    'walker.pedestrian.0027':
    'pedestrian',
    'walker.pedestrian.0030':
    'pedestrian',
    'walker.pedestrian.0031':
    'pedestrian',
    'walker.pedestrian.0032':
    'pedestrian',
    'walker.pedestrian.0034':
    'pedestrian',
    'walker.pedestrian.0035':
    'pedestrian',
    'walker.pedestrian.0041':
    'pedestrian',
    'walker.pedestrian.0042':
    'pedestrian',
    'walker.pedestrian.0046':
    'pedestrian',
    'walker.pedestrian.0047':
    'pedestrian',
    'static.prop.dirtdebris01':
    'others',
    'static.prop.dirtdebris02':
    'others'
})
eval_cfg = dict(
    dist_ths=[0.5, 1.0, 2.0, 4.0],
    dist_th_tp=2.0,
    min_recall=0.1,
    min_precision=0.1,
    mean_ap_weight=5,
    class_names=[
        'car', 'van', 'truck', 'bicycle', 'traffic_sign', 'traffic_cone',
        'traffic_light', 'pedestrian'
    ],
    tp_metrics=['trans_err', 'scale_err', 'orient_err', 'vel_err'],
    err_name_maping=dict(
        trans_err='mATE',
        scale_err='mASE',
        orient_err='mAOE',
        vel_err='mAVE',
        attr_err='mAAE'),
    class_range=dict(
        car=(50, 50),
        van=(50, 50),
        truck=(50, 50),
        bicycle=(40, 40),
        traffic_sign=(30, 30),
        traffic_cone=(30, 30),
        traffic_light=(30, 30),
        pedestrian=(40, 40)))
use_memory = True
num_gpus = 1
batch_size = 1
num_iters_per_epoch = 234769
num_epochs = 6
llm_path = '/root/autodl-tmp/Orion_modify/ckpts/pretrain_qformer/'
use_gen_token = True
use_col_loss = True
collect_keys = [
    'lidar2img', 'cam_intrinsic', 'timestamp', 'ego_pose', 'ego_pose_inv',
    'command'
]
model = dict(
    type='Orion',
    save_path='./results_planning_only/',
    use_grid_mask=True,
    frozen=False,
    use_lora=True,
    tokenizer='/root/autodl-tmp/Orion_modify/ckpts/pretrain_qformer/',
    lm_head='/root/autodl-tmp/Orion_modify/ckpts/pretrain_qformer/',
    use_gen_token=True,
    use_diff_decoder=False,
    use_col_loss=True,
    loss_plan_reg=dict(type='L1Loss', loss_weight=3.0),
    loss_plan_bound=dict(
        type='PlanMapBoundLoss', loss_weight=3.0, dis_thresh=1.0),
    loss_plan_col=dict(type='PlanCollisionLoss', loss_weight=1.0),
    loss_vae_gen=dict(type='ProbabilisticLoss', loss_weight=3.0),
    img_backbone=dict(
        type='EVAViT',
        img_size=640,
        patch_size=16,
        window_size=16,
        in_chans=3,
        embed_dim=1024,
        depth=24,
        num_heads=16,
        mlp_ratio=2.6666666666666665,
        window_block_indexes=[
            0, 1, 3, 4, 6, 7, 9, 10, 12, 13, 15, 16, 18, 19, 21, 22
        ],
        qkv_bias=True,
        drop_path_rate=0.3,
        flash_attn=True,
        with_cp=True,
        frozen=False),
    map_head=dict(
        type='OrionHeadM',
        num_classes=6,
        in_channels=1024,
        out_dims=4096,
        memory_len=600,
        with_mask=True,
        topk_proposals=300,
        num_lane=1800,
        num_lanes_one2one=300,
        k_one2many=5,
        lambda_one2many=1.0,
        num_extra=256,
        n_control=11,
        pc_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0],
        code_weights=[1.0, 1.0],
        score_threshold=0.2,
        transformer=dict(
            type='PETRTemporalTransformer',
            input_dimension=256,
            output_dimension=256,
            num_layers=6,
            embed_dims=256,
            num_heads=8,
            feedforward_dims=2048,
            dropout=0.1,
            with_cp=True,
            flash_attn=True),
        train_cfg=dict(
            assigner=dict(
                type='LaneHungarianAssigner',
                cls_cost=dict(type='FocalLossCost', weight=1.5),
                reg_cost=dict(type='LaneL1Cost', weight=0.02),
                iou_cost=dict(type='IoUCost', weight=0.0))),
        loss_cls=dict(
            type='FocalLoss',
            use_sigmoid=True,
            gamma=2.0,
            alpha=0.25,
            loss_weight=1.5),
        loss_bbox=dict(type='L1Loss', loss_weight=0.02),
        loss_dir=dict(type='PtsDirCosLoss', loss_weight=0.0)),
    pts_bbox_head=dict(
        type='OrionHead',
        num_classes=9,
        in_channels=1024,
        out_dims=4096,
        num_query=600,
        with_mask=True,
        memory_len=600,
        topk_proposals=300,
        num_propagated=300,
        num_extra=256,
        n_control=11,
        match_with_velo=False,
        pred_traffic_light_state=True,
        use_col_loss=True,
        use_memory=True,
        scalar=10,
        noise_scale=1.0,
        dn_weight=1.0,
        split=0.75,
        use_pe=False,
        motion_transformer_decoder=dict(
            type='OrionTransformerDecoder',
            num_layers=1,
            embed_dims=256,
            num_heads=8,
            dropout=0.0,
            feedforward_dims=512,
            with_cp=True,
            flash_attn=True,
            return_intermediate=False),
        code_weights=[2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],
        score_threshold=0.2,
        class_agnostic_nms=dict(
            classes=[0, 1, 2, 3, 4, 5, 6, 7, 8],
            compensate=[0, 0, 0.3, 0, 0, 0, 0, 0.3, 0],
            pre_max_size=1000,
            post_max_size=300,
            nms_thr=0.1),
        memory_decoder_transformer=dict(
            type='OrionTransformerDecoder',
            num_layers=1,
            embed_dims=256,
            num_heads=8,
            dropout=0.0,
            feedforward_dims=512,
            with_cp=True,
            flash_attn=True,
            return_intermediate=False),
        transformer=dict(
            type='PETRTemporalTransformer',
            input_dimension=256,
            output_dimension=256,
            num_layers=6,
            embed_dims=256,
            num_heads=8,
            feedforward_dims=2048,
            dropout=0.1,
            with_cp=True,
            flash_attn=True),
        bbox_coder=dict(
            type='CustomNMSFreeCoder',
            post_center_range=[-61.2, -61.2, -10.0, 61.2, 61.2, 10.0],
            pc_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0],
            max_num=300,
            voxel_size=[0.2, 0.2, 8],
            num_classes=9),
        loss_cls=dict(
            type='FocalLoss',
            use_sigmoid=True,
            gamma=2.0,
            alpha=0.25,
            loss_weight=2.0),
        loss_traffic=dict(
            type='FocalLoss',
            use_sigmoid=True,
            gamma=2.0,
            alpha=0.25,
            loss_weight=2.0),
        loss_bbox=dict(type='L1Loss', loss_weight=0.25),
        loss_iou=dict(type='GIoULoss', loss_weight=0.0)),
    train_cfg=dict(
        pts=dict(
            grid_size=[512, 512, 1],
            voxel_size=[0.2, 0.2, 8],
            point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0],
            out_size_factor=4,
            assigner=dict(
                type='HungarianAssigner3D',
                cls_cost=dict(type='FocalLossCost', weight=2.0),
                reg_cost=dict(type='BBox3DL1Cost', weight=0.25),
                iou_cost=dict(type='IoUCost', weight=0.0),
                pc_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]))))
info_root = '/root/autodl-tmp/Orion_modify/data/infos'
map_root = '/root/autodl-tmp/Orion_modify/data/bench2drive/maps'
map_file = '/root/autodl-tmp/Orion_modify/data/infos/b2d_map_infos.pkl'
ann_file_train = '/root/autodl-tmp/Orion_modify/data/infos/b2d_infos_train.pkl'
ann_file_val = '/root/autodl-tmp/Orion_modify/data/infos/b2d_infos_val.pkl'
ann_file_test = '/root/autodl-tmp/Orion_modify/data/infos/b2d_infos_val.pkl'
inference_only_pipeline = [
    dict(
        type='LoadMultiViewImageFromFilesInCeph',
        to_float32=True,
        file_client_args=dict(backend='disk'),
        img_root='/root/autodl-tmp/Orion_modify/data/bench2drive'),
    dict(
        type='NormalizeMultiviewImage',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='PadMultiViewImage', size_divisor=32),
    dict(
        type='MultiScaleFlipAug3D',
        img_scale=(1600, 900),
        pts_scale_ratio=1,
        flip=False,
        transforms=[
            dict(
                type='DefaultFormatBundle3D',
                class_names=[
                    'car', 'van', 'truck', 'bicycle', 'traffic_sign',
                    'traffic_cone', 'traffic_light', 'pedestrian', 'others'
                ],
                with_label=False),
            dict(
                type='CustomCollect3D',
                keys=['img', 'timestamp', 'l2g_r_mat', 'l2g_t', 'command'])
        ])
]
optimizer = dict(
    constructor='LearningRateDecayOptimizerConstructor',
    type='AdamW',
    lr=8e-05,
    betas=(0.9, 0.999),
    weight_decay=1e-05,
    paramwise_cfg=dict(
        decay_rate=0.9,
        head_decay_rate=4.0,
        lm_head_decay_rate=0.1,
        decay_type='vit_wise',
        num_layers=24))
optimizer_config = dict(
    type='Fp16OptimizerHook',
    loss_scale='dynamic',
    grad_clip=dict(max_norm=35, norm_type=2))
lr_config = dict(
    policy='CosineAnnealing',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.3333333333333333,
    min_lr_ratio=0.001)
find_unused_parameters = False
runner = dict(type='IterBasedRunner', max_iters=1408614)
gpu_ids = range(0, 1)

2025-11-02 19:57:17,871 - mmdet - INFO - Set random seed to 0, deterministic: False
Name of parameter - Initialization information

position_range - torch.Size([6]): 
The value is the same before and after calling `init_weights` of Orion  

coords_d - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.code_weights - torch.Size([10]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.match_costs - torch.Size([10]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.pc_range - torch.Size([6]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.traj_branches.0.0.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.traj_branches.0.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.traj_branches.0.2.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.traj_branches.0.2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.traj_branches.0.4.weight - torch.Size([12, 512]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.traj_branches.0.4.bias - torch.Size([12]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.traj_cls_branches.0.0.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.traj_cls_branches.0.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.traj_cls_branches.0.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.traj_cls_branches.0.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.traj_cls_branches.0.3.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.traj_cls_branches.0.3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.traj_cls_branches.0.4.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.traj_cls_branches.0.4.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.traj_cls_branches.0.6.weight - torch.Size([1, 512]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.traj_cls_branches.0.6.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.cls_branches.0.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.cls_branches.0.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.cls_branches.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.cls_branches.0.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.cls_branches.0.3.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.cls_branches.0.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.cls_branches.0.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.cls_branches.0.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.cls_branches.0.6.weight - torch.Size([9, 256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.cls_branches.0.6.bias - torch.Size([9]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.reg_branches.0.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.reg_branches.0.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.reg_branches.0.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.reg_branches.0.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.reg_branches.0.4.weight - torch.Size([10, 256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.reg_branches.0.4.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.input_projection.weight - torch.Size([256, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.input_projection.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.output_projection.weight - torch.Size([4096, 256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.output_projection.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.reference_points.weight - torch.Size([600, 3]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.pseudo_reference_points.weight - torch.Size([300, 3]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.query_embedding.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.can_bus_embed.0.weight - torch.Size([1024, 89]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.can_bus_embed.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.can_bus_embed.2.weight - torch.Size([4096, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.can_bus_embed.2.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.0.transformer_layers.0.attn.in_proj_weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.0.transformer_layers.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.0.transformer_layers.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.transformer.query_decoder._layers.0.transformer_layers.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.0.transformer_layers.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.0.transformer_layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.0.transformer_layers.2.attn.in_proj_weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.0.transformer_layers.2.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.0.transformer_layers.2.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.transformer.query_decoder._layers.0.transformer_layers.2.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.0.transformer_layers.3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.0.transformer_layers.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.0.transformer_layers.4._layers.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.transformer.query_decoder._layers.0.transformer_layers.4._layers.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.0.transformer_layers.4._layers.3.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.transformer.query_decoder._layers.0.transformer_layers.4._layers.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.0.transformer_layers.5.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.0.transformer_layers.5.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.1.transformer_layers.0.attn.in_proj_weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.1.transformer_layers.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.1.transformer_layers.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.transformer.query_decoder._layers.1.transformer_layers.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.1.transformer_layers.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.1.transformer_layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.1.transformer_layers.2.attn.in_proj_weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.1.transformer_layers.2.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.1.transformer_layers.2.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.transformer.query_decoder._layers.1.transformer_layers.2.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.1.transformer_layers.3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.1.transformer_layers.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.1.transformer_layers.4._layers.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.transformer.query_decoder._layers.1.transformer_layers.4._layers.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.1.transformer_layers.4._layers.3.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.transformer.query_decoder._layers.1.transformer_layers.4._layers.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.1.transformer_layers.5.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.1.transformer_layers.5.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.2.transformer_layers.0.attn.in_proj_weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.2.transformer_layers.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.2.transformer_layers.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.transformer.query_decoder._layers.2.transformer_layers.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.2.transformer_layers.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.2.transformer_layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.2.transformer_layers.2.attn.in_proj_weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.2.transformer_layers.2.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.2.transformer_layers.2.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.transformer.query_decoder._layers.2.transformer_layers.2.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.2.transformer_layers.3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.2.transformer_layers.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.2.transformer_layers.4._layers.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.transformer.query_decoder._layers.2.transformer_layers.4._layers.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.2.transformer_layers.4._layers.3.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.transformer.query_decoder._layers.2.transformer_layers.4._layers.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.2.transformer_layers.5.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.2.transformer_layers.5.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.3.transformer_layers.0.attn.in_proj_weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.3.transformer_layers.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.3.transformer_layers.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.transformer.query_decoder._layers.3.transformer_layers.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.3.transformer_layers.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.3.transformer_layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.3.transformer_layers.2.attn.in_proj_weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.3.transformer_layers.2.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.3.transformer_layers.2.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.transformer.query_decoder._layers.3.transformer_layers.2.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.3.transformer_layers.3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.3.transformer_layers.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.3.transformer_layers.4._layers.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.transformer.query_decoder._layers.3.transformer_layers.4._layers.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.3.transformer_layers.4._layers.3.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.transformer.query_decoder._layers.3.transformer_layers.4._layers.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.3.transformer_layers.5.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.3.transformer_layers.5.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.4.transformer_layers.0.attn.in_proj_weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.4.transformer_layers.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.4.transformer_layers.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.transformer.query_decoder._layers.4.transformer_layers.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.4.transformer_layers.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.4.transformer_layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.4.transformer_layers.2.attn.in_proj_weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.4.transformer_layers.2.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.4.transformer_layers.2.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.transformer.query_decoder._layers.4.transformer_layers.2.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.4.transformer_layers.3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.4.transformer_layers.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.4.transformer_layers.4._layers.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.transformer.query_decoder._layers.4.transformer_layers.4._layers.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.4.transformer_layers.4._layers.3.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.transformer.query_decoder._layers.4.transformer_layers.4._layers.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.4.transformer_layers.5.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.4.transformer_layers.5.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.5.transformer_layers.0.attn.in_proj_weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.5.transformer_layers.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.5.transformer_layers.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.transformer.query_decoder._layers.5.transformer_layers.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.5.transformer_layers.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.5.transformer_layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.5.transformer_layers.2.attn.in_proj_weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.5.transformer_layers.2.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.5.transformer_layers.2.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.transformer.query_decoder._layers.5.transformer_layers.2.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.5.transformer_layers.3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.5.transformer_layers.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.5.transformer_layers.4._layers.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.transformer.query_decoder._layers.5.transformer_layers.4._layers.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.5.transformer_layers.4._layers.3.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.transformer.query_decoder._layers.5.transformer_layers.4._layers.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.5.transformer_layers.5.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.transformer.query_decoder._layers.5.transformer_layers.5.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.motion_decoder._layers.0.transformer_layers.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.motion_decoder._layers.0.transformer_layers.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.motion_decoder._layers.0.transformer_layers.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.motion_decoder._layers.0.transformer_layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.motion_decoder._layers.0.transformer_layers.2._layers.0.weight - torch.Size([512, 256]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.motion_decoder._layers.0.transformer_layers.2._layers.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.motion_decoder._layers.0.transformer_layers.2._layers.3.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.motion_decoder._layers.0.transformer_layers.2._layers.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.motion_decoder._layers.0.transformer_layers.3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.motion_decoder._layers.0.transformer_layers.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.motion_mode_query.weight - torch.Size([6, 256]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.memory_query.weight - torch.Size([16, 256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.scene_time_embedding.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.scene_time_embedding.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.scene_time_embedding.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.scene_time_embedding.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.memory_decoder_cq._layers.0.transformer_layers.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.memory_decoder_cq._layers.0.transformer_layers.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.memory_decoder_cq._layers.0.transformer_layers.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.memory_decoder_cq._layers.0.transformer_layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.memory_decoder_cq._layers.0.transformer_layers.2._layers.0.weight - torch.Size([512, 256]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.memory_decoder_cq._layers.0.transformer_layers.2._layers.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.memory_decoder_cq._layers.0.transformer_layers.2._layers.3.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.memory_decoder_cq._layers.0.transformer_layers.2._layers.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.memory_decoder_cq._layers.0.transformer_layers.3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.memory_decoder_cq._layers.0.transformer_layers.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.memory_decoder_mq._layers.0.transformer_layers.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.memory_decoder_mq._layers.0.transformer_layers.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.memory_decoder_mq._layers.0.transformer_layers.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.memory_decoder_mq._layers.0.transformer_layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.memory_decoder_mq._layers.0.transformer_layers.2._layers.0.weight - torch.Size([512, 256]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.memory_decoder_mq._layers.0.transformer_layers.2._layers.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.memory_decoder_mq._layers.0.transformer_layers.2._layers.3.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in OrionHead  

pts_bbox_head.memory_decoder_mq._layers.0.transformer_layers.2._layers.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.memory_decoder_mq._layers.0.transformer_layers.3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.memory_decoder_mq._layers.0.transformer_layers.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.tl_branches.0.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.tl_branches.0.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.tl_branches.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.tl_branches.0.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.tl_branches.0.3.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.tl_branches.0.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.tl_branches.0.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.tl_branches.0.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.tl_branches.0.6.weight - torch.Size([4, 256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.tl_branches.0.6.bias - torch.Size([4]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.query_pos.0.weight - torch.Size([256, 396]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.query_pos.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.query_pos.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.query_pos.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.time_embedding.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.time_embedding.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.time_embedding.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.time_embedding.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.ego_pose_pe.reduce.0.weight - torch.Size([256, 156]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.ego_pose_pe.reduce.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.ego_pose_pe.gamma.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.ego_pose_pe.gamma.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.ego_pose_pe.beta.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of Orion  

pts_bbox_head.ego_pose_pe.beta.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.pos_embed - torch.Size([1, 197, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.patch_embed.proj.weight - torch.Size([1024, 3, 16, 16]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.patch_embed.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.0.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.0.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.0.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.0.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.0.attn.q_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.0.attn.k_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.0.attn.v_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.0.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.0.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.0.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.0.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.0.mlp.w1.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.0.mlp.w1.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.0.mlp.w2.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.0.mlp.w2.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.0.mlp.ffn_ln.weight - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.0.mlp.ffn_ln.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.0.mlp.w3.weight - torch.Size([1024, 2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.0.mlp.w3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.1.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.1.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.1.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.1.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.1.attn.q_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.1.attn.k_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.1.attn.v_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.1.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.1.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.1.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.1.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.1.mlp.w1.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.1.mlp.w1.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.1.mlp.w2.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.1.mlp.w2.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.1.mlp.ffn_ln.weight - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.1.mlp.ffn_ln.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.1.mlp.w3.weight - torch.Size([1024, 2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.1.mlp.w3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.2.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.2.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.2.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.2.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.2.attn.q_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.2.attn.k_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.2.attn.v_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.2.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.2.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.2.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.2.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.2.mlp.w1.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.2.mlp.w1.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.2.mlp.w2.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.2.mlp.w2.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.2.mlp.ffn_ln.weight - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.2.mlp.ffn_ln.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.2.mlp.w3.weight - torch.Size([1024, 2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.2.mlp.w3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.3.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.3.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.3.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.3.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.3.attn.q_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.3.attn.k_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.3.attn.v_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.3.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.3.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.3.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.3.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.3.mlp.w1.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.3.mlp.w1.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.3.mlp.w2.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.3.mlp.w2.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.3.mlp.ffn_ln.weight - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.3.mlp.ffn_ln.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.3.mlp.w3.weight - torch.Size([1024, 2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.3.mlp.w3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.4.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.4.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.4.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.4.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.4.attn.q_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.4.attn.k_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.4.attn.v_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.4.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.4.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.4.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.4.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.4.mlp.w1.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.4.mlp.w1.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.4.mlp.w2.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.4.mlp.w2.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.4.mlp.ffn_ln.weight - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.4.mlp.ffn_ln.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.4.mlp.w3.weight - torch.Size([1024, 2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.4.mlp.w3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.5.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.5.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.5.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.5.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.5.attn.q_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.5.attn.k_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.5.attn.v_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.5.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.5.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.5.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.5.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.5.mlp.w1.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.5.mlp.w1.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.5.mlp.w2.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.5.mlp.w2.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.5.mlp.ffn_ln.weight - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.5.mlp.ffn_ln.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.5.mlp.w3.weight - torch.Size([1024, 2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.5.mlp.w3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.6.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.6.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.6.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.6.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.6.attn.q_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.6.attn.k_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.6.attn.v_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.6.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.6.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.6.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.6.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.6.mlp.w1.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.6.mlp.w1.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.6.mlp.w2.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.6.mlp.w2.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.6.mlp.ffn_ln.weight - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.6.mlp.ffn_ln.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.6.mlp.w3.weight - torch.Size([1024, 2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.6.mlp.w3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.7.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.7.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.7.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.7.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.7.attn.q_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.7.attn.k_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.7.attn.v_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.7.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.7.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.7.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.7.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.7.mlp.w1.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.7.mlp.w1.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.7.mlp.w2.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.7.mlp.w2.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.7.mlp.ffn_ln.weight - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.7.mlp.ffn_ln.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.7.mlp.w3.weight - torch.Size([1024, 2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.7.mlp.w3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.8.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.8.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.8.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.8.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.8.attn.q_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.8.attn.k_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.8.attn.v_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.8.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.8.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.8.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.8.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.8.mlp.w1.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.8.mlp.w1.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.8.mlp.w2.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.8.mlp.w2.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.8.mlp.ffn_ln.weight - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.8.mlp.ffn_ln.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.8.mlp.w3.weight - torch.Size([1024, 2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.8.mlp.w3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.9.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.9.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.9.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.9.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.9.attn.q_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.9.attn.k_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.9.attn.v_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.9.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.9.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.9.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.9.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.9.mlp.w1.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.9.mlp.w1.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.9.mlp.w2.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.9.mlp.w2.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.9.mlp.ffn_ln.weight - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.9.mlp.ffn_ln.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.9.mlp.w3.weight - torch.Size([1024, 2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.9.mlp.w3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.10.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.10.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.10.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.10.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.10.attn.q_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.10.attn.k_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.10.attn.v_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.10.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.10.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.10.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.10.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.10.mlp.w1.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.10.mlp.w1.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.10.mlp.w2.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.10.mlp.w2.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.10.mlp.ffn_ln.weight - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.10.mlp.ffn_ln.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.10.mlp.w3.weight - torch.Size([1024, 2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.10.mlp.w3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.11.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.11.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.11.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.11.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.11.attn.q_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.11.attn.k_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.11.attn.v_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.11.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.11.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.11.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.11.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.11.mlp.w1.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.11.mlp.w1.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.11.mlp.w2.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.11.mlp.w2.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.11.mlp.ffn_ln.weight - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.11.mlp.ffn_ln.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.11.mlp.w3.weight - torch.Size([1024, 2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.11.mlp.w3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.12.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.12.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.12.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.12.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.12.attn.q_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.12.attn.k_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.12.attn.v_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.12.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.12.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.12.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.12.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.12.mlp.w1.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.12.mlp.w1.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.12.mlp.w2.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.12.mlp.w2.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.12.mlp.ffn_ln.weight - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.12.mlp.ffn_ln.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.12.mlp.w3.weight - torch.Size([1024, 2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.12.mlp.w3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.13.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.13.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.13.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.13.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.13.attn.q_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.13.attn.k_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.13.attn.v_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.13.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.13.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.13.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.13.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.13.mlp.w1.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.13.mlp.w1.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.13.mlp.w2.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.13.mlp.w2.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.13.mlp.ffn_ln.weight - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.13.mlp.ffn_ln.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.13.mlp.w3.weight - torch.Size([1024, 2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.13.mlp.w3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.14.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.14.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.14.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.14.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.14.attn.q_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.14.attn.k_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.14.attn.v_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.14.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.14.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.14.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.14.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.14.mlp.w1.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.14.mlp.w1.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.14.mlp.w2.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.14.mlp.w2.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.14.mlp.ffn_ln.weight - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.14.mlp.ffn_ln.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.14.mlp.w3.weight - torch.Size([1024, 2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.14.mlp.w3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.15.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.15.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.15.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.15.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.15.attn.q_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.15.attn.k_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.15.attn.v_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.15.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.15.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.15.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.15.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.15.mlp.w1.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.15.mlp.w1.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.15.mlp.w2.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.15.mlp.w2.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.15.mlp.ffn_ln.weight - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.15.mlp.ffn_ln.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.15.mlp.w3.weight - torch.Size([1024, 2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.15.mlp.w3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.16.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.16.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.16.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.16.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.16.attn.q_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.16.attn.k_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.16.attn.v_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.16.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.16.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.16.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.16.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.16.mlp.w1.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.16.mlp.w1.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.16.mlp.w2.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.16.mlp.w2.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.16.mlp.ffn_ln.weight - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.16.mlp.ffn_ln.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.16.mlp.w3.weight - torch.Size([1024, 2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.16.mlp.w3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.17.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.17.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.17.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.17.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.17.attn.q_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.17.attn.k_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.17.attn.v_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.17.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.17.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.17.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.17.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.17.mlp.w1.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.17.mlp.w1.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.17.mlp.w2.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.17.mlp.w2.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.17.mlp.ffn_ln.weight - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.17.mlp.ffn_ln.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.17.mlp.w3.weight - torch.Size([1024, 2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.17.mlp.w3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.18.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.18.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.18.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.18.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.18.attn.q_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.18.attn.k_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.18.attn.v_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.18.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.18.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.18.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.18.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.18.mlp.w1.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.18.mlp.w1.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.18.mlp.w2.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.18.mlp.w2.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.18.mlp.ffn_ln.weight - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.18.mlp.ffn_ln.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.18.mlp.w3.weight - torch.Size([1024, 2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.18.mlp.w3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.19.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.19.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.19.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.19.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.19.attn.q_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.19.attn.k_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.19.attn.v_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.19.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.19.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.19.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.19.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.19.mlp.w1.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.19.mlp.w1.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.19.mlp.w2.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.19.mlp.w2.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.19.mlp.ffn_ln.weight - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.19.mlp.ffn_ln.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.19.mlp.w3.weight - torch.Size([1024, 2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.19.mlp.w3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.20.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.20.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.20.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.20.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.20.attn.q_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.20.attn.k_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.20.attn.v_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.20.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.20.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.20.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.20.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.20.mlp.w1.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.20.mlp.w1.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.20.mlp.w2.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.20.mlp.w2.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.20.mlp.ffn_ln.weight - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.20.mlp.ffn_ln.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.20.mlp.w3.weight - torch.Size([1024, 2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.20.mlp.w3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.21.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.21.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.21.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.21.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.21.attn.q_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.21.attn.k_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.21.attn.v_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.21.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.21.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.21.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.21.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.21.mlp.w1.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.21.mlp.w1.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.21.mlp.w2.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.21.mlp.w2.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.21.mlp.ffn_ln.weight - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.21.mlp.ffn_ln.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.21.mlp.w3.weight - torch.Size([1024, 2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.21.mlp.w3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.22.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.22.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.22.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.22.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.22.attn.q_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.22.attn.k_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.22.attn.v_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.22.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.22.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.22.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.22.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.22.mlp.w1.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.22.mlp.w1.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.22.mlp.w2.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.22.mlp.w2.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.22.mlp.ffn_ln.weight - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.22.mlp.ffn_ln.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.22.mlp.w3.weight - torch.Size([1024, 2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.22.mlp.w3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.23.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.23.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.23.attn.q_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.23.attn.v_bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.23.attn.q_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.23.attn.k_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.23.attn.v_proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.23.attn.proj.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.23.attn.proj.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.23.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.23.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.23.mlp.w1.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.23.mlp.w1.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.23.mlp.w2.weight - torch.Size([2730, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.23.mlp.w2.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.23.mlp.ffn_ln.weight - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.23.mlp.ffn_ln.bias - torch.Size([2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.23.mlp.w3.weight - torch.Size([1024, 2730]): 
The value is the same before and after calling `init_weights` of Orion  

img_backbone.blocks.23.mlp.w3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.code_weights - torch.Size([2]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.match_costs - torch.Size([2]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.pc_range - torch.Size([6]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.cls_branches.0.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.cls_branches.0.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.cls_branches.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.cls_branches.0.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.cls_branches.0.3.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.cls_branches.0.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.cls_branches.0.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.cls_branches.0.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.cls_branches.0.6.weight - torch.Size([6, 256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.cls_branches.0.6.bias - torch.Size([6]): 
Initialized by user-defined `init_weights` in OrionHeadM  

map_head.reg_branches.0.0.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in OrionHeadM  

map_head.reg_branches.0.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.reg_branches.0.2.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in OrionHeadM  

map_head.reg_branches.0.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.reg_branches.0.4.weight - torch.Size([33, 256]): 
Initialized by user-defined `init_weights` in OrionHeadM  

map_head.reg_branches.0.4.bias - torch.Size([33]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.input_projection.weight - torch.Size([256, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.input_projection.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.output_projection.weight - torch.Size([4096, 256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.output_projection.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.reference_points_lane.weight - torch.Size([3, 256]): 
Initialized by user-defined `init_weights` in OrionHeadM  

map_head.reference_points_lane.bias - torch.Size([3]): 
Initialized by user-defined `init_weights` in OrionHeadM  

map_head.points_embedding_lane.weight - torch.Size([11, 256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.instance_embedding_lane.weight - torch.Size([1800, 256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.query_embedding.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.0.transformer_layers.0.attn.in_proj_weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.0.transformer_layers.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.0.transformer_layers.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in OrionHeadM  

map_head.transformer.query_decoder._layers.0.transformer_layers.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.0.transformer_layers.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.0.transformer_layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.0.transformer_layers.2.attn.in_proj_weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.0.transformer_layers.2.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.0.transformer_layers.2.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in OrionHeadM  

map_head.transformer.query_decoder._layers.0.transformer_layers.2.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.0.transformer_layers.3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.0.transformer_layers.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.0.transformer_layers.4._layers.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in OrionHeadM  

map_head.transformer.query_decoder._layers.0.transformer_layers.4._layers.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.0.transformer_layers.4._layers.3.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in OrionHeadM  

map_head.transformer.query_decoder._layers.0.transformer_layers.4._layers.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.0.transformer_layers.5.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.0.transformer_layers.5.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.1.transformer_layers.0.attn.in_proj_weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.1.transformer_layers.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.1.transformer_layers.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in OrionHeadM  

map_head.transformer.query_decoder._layers.1.transformer_layers.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.1.transformer_layers.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.1.transformer_layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.1.transformer_layers.2.attn.in_proj_weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.1.transformer_layers.2.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.1.transformer_layers.2.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in OrionHeadM  

map_head.transformer.query_decoder._layers.1.transformer_layers.2.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.1.transformer_layers.3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.1.transformer_layers.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.1.transformer_layers.4._layers.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in OrionHeadM  

map_head.transformer.query_decoder._layers.1.transformer_layers.4._layers.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.1.transformer_layers.4._layers.3.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in OrionHeadM  

map_head.transformer.query_decoder._layers.1.transformer_layers.4._layers.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.1.transformer_layers.5.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.1.transformer_layers.5.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.2.transformer_layers.0.attn.in_proj_weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.2.transformer_layers.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.2.transformer_layers.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in OrionHeadM  

map_head.transformer.query_decoder._layers.2.transformer_layers.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.2.transformer_layers.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.2.transformer_layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.2.transformer_layers.2.attn.in_proj_weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.2.transformer_layers.2.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.2.transformer_layers.2.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in OrionHeadM  

map_head.transformer.query_decoder._layers.2.transformer_layers.2.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.2.transformer_layers.3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.2.transformer_layers.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.2.transformer_layers.4._layers.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in OrionHeadM  

map_head.transformer.query_decoder._layers.2.transformer_layers.4._layers.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.2.transformer_layers.4._layers.3.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in OrionHeadM  

map_head.transformer.query_decoder._layers.2.transformer_layers.4._layers.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.2.transformer_layers.5.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.2.transformer_layers.5.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.3.transformer_layers.0.attn.in_proj_weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.3.transformer_layers.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.3.transformer_layers.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in OrionHeadM  

map_head.transformer.query_decoder._layers.3.transformer_layers.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.3.transformer_layers.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.3.transformer_layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.3.transformer_layers.2.attn.in_proj_weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.3.transformer_layers.2.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.3.transformer_layers.2.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in OrionHeadM  

map_head.transformer.query_decoder._layers.3.transformer_layers.2.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.3.transformer_layers.3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.3.transformer_layers.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.3.transformer_layers.4._layers.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in OrionHeadM  

map_head.transformer.query_decoder._layers.3.transformer_layers.4._layers.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.3.transformer_layers.4._layers.3.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in OrionHeadM  

map_head.transformer.query_decoder._layers.3.transformer_layers.4._layers.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.3.transformer_layers.5.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.3.transformer_layers.5.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.4.transformer_layers.0.attn.in_proj_weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.4.transformer_layers.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.4.transformer_layers.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in OrionHeadM  

map_head.transformer.query_decoder._layers.4.transformer_layers.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.4.transformer_layers.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.4.transformer_layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.4.transformer_layers.2.attn.in_proj_weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.4.transformer_layers.2.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.4.transformer_layers.2.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in OrionHeadM  

map_head.transformer.query_decoder._layers.4.transformer_layers.2.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.4.transformer_layers.3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.4.transformer_layers.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.4.transformer_layers.4._layers.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in OrionHeadM  

map_head.transformer.query_decoder._layers.4.transformer_layers.4._layers.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.4.transformer_layers.4._layers.3.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in OrionHeadM  

map_head.transformer.query_decoder._layers.4.transformer_layers.4._layers.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.4.transformer_layers.5.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.4.transformer_layers.5.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.5.transformer_layers.0.attn.in_proj_weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.5.transformer_layers.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.5.transformer_layers.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in OrionHeadM  

map_head.transformer.query_decoder._layers.5.transformer_layers.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.5.transformer_layers.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.5.transformer_layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.5.transformer_layers.2.attn.in_proj_weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.5.transformer_layers.2.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.5.transformer_layers.2.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in OrionHeadM  

map_head.transformer.query_decoder._layers.5.transformer_layers.2.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.5.transformer_layers.3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.5.transformer_layers.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.5.transformer_layers.4._layers.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in OrionHeadM  

map_head.transformer.query_decoder._layers.5.transformer_layers.4._layers.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.5.transformer_layers.4._layers.3.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in OrionHeadM  

map_head.transformer.query_decoder._layers.5.transformer_layers.4._layers.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.5.transformer_layers.5.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

map_head.transformer.query_decoder._layers.5.transformer_layers.5.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

position_encoder.0.weight - torch.Size([1024, 192]): 
The value is the same before and after calling `init_weights` of Orion  

position_encoder.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of Orion  

position_encoder.2.weight - torch.Size([256, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

position_encoder.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.embed_tokens.weight - torch.Size([32001, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.0.mlp.gate_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.0.mlp.up_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.0.mlp.down_proj.weight - torch.Size([4096, 11008]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.0.input_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.0.post_attention_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.1.mlp.gate_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.1.mlp.up_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.1.mlp.down_proj.weight - torch.Size([4096, 11008]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.1.input_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.1.post_attention_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.2.mlp.gate_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.2.mlp.up_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.2.mlp.down_proj.weight - torch.Size([4096, 11008]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.2.input_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.2.post_attention_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.3.mlp.gate_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.3.mlp.up_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.3.mlp.down_proj.weight - torch.Size([4096, 11008]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.3.input_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.3.post_attention_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.4.mlp.gate_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.4.mlp.up_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.4.mlp.down_proj.weight - torch.Size([4096, 11008]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.4.input_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.4.post_attention_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.5.mlp.gate_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.5.mlp.up_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.5.mlp.down_proj.weight - torch.Size([4096, 11008]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.5.input_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.5.post_attention_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.6.mlp.gate_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.6.mlp.up_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.6.mlp.down_proj.weight - torch.Size([4096, 11008]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.6.input_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.6.post_attention_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.7.mlp.gate_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.7.mlp.up_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.7.mlp.down_proj.weight - torch.Size([4096, 11008]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.7.input_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.7.post_attention_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.8.mlp.gate_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.8.mlp.up_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.8.mlp.down_proj.weight - torch.Size([4096, 11008]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.8.input_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.8.post_attention_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.9.mlp.gate_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.9.mlp.up_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.9.mlp.down_proj.weight - torch.Size([4096, 11008]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.9.input_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.9.post_attention_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.10.mlp.gate_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.10.mlp.up_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.10.mlp.down_proj.weight - torch.Size([4096, 11008]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.10.input_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.10.post_attention_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.11.mlp.gate_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.11.mlp.up_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.11.mlp.down_proj.weight - torch.Size([4096, 11008]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.11.input_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.11.post_attention_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.12.mlp.gate_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.12.mlp.up_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.12.mlp.down_proj.weight - torch.Size([4096, 11008]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.12.input_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.12.post_attention_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.13.mlp.gate_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.13.mlp.up_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.13.mlp.down_proj.weight - torch.Size([4096, 11008]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.13.input_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.13.post_attention_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.14.mlp.gate_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.14.mlp.up_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.14.mlp.down_proj.weight - torch.Size([4096, 11008]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.14.input_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.14.post_attention_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.15.mlp.gate_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.15.mlp.up_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.15.mlp.down_proj.weight - torch.Size([4096, 11008]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.15.input_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.15.post_attention_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.16.self_attn.k_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.16.mlp.gate_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.16.mlp.up_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.16.mlp.down_proj.weight - torch.Size([4096, 11008]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.16.input_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.16.post_attention_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.17.self_attn.k_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.17.mlp.gate_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.17.mlp.up_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.17.mlp.down_proj.weight - torch.Size([4096, 11008]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.17.input_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.17.post_attention_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.18.self_attn.k_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.18.mlp.gate_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.18.mlp.up_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.18.mlp.down_proj.weight - torch.Size([4096, 11008]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.18.input_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.18.post_attention_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.19.self_attn.k_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.19.mlp.gate_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.19.mlp.up_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.19.mlp.down_proj.weight - torch.Size([4096, 11008]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.19.input_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.19.post_attention_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.20.self_attn.k_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.20.mlp.gate_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.20.mlp.up_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.20.mlp.down_proj.weight - torch.Size([4096, 11008]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.20.input_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.20.post_attention_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.21.self_attn.k_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.21.mlp.gate_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.21.mlp.up_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.21.mlp.down_proj.weight - torch.Size([4096, 11008]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.21.input_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.21.post_attention_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.22.self_attn.k_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.22.self_attn.o_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.22.mlp.gate_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.22.mlp.up_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.22.mlp.down_proj.weight - torch.Size([4096, 11008]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.22.input_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.22.post_attention_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.23.self_attn.k_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.23.self_attn.o_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.23.mlp.gate_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.23.mlp.up_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.23.mlp.down_proj.weight - torch.Size([4096, 11008]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.23.input_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.23.post_attention_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.24.self_attn.k_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.24.self_attn.o_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.24.mlp.gate_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.24.mlp.up_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.24.mlp.down_proj.weight - torch.Size([4096, 11008]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.24.input_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.24.post_attention_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.25.self_attn.k_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.25.self_attn.o_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.25.mlp.gate_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.25.mlp.up_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.25.mlp.down_proj.weight - torch.Size([4096, 11008]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.25.input_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.25.post_attention_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.26.self_attn.k_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.26.self_attn.o_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.26.mlp.gate_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.26.mlp.up_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.26.mlp.down_proj.weight - torch.Size([4096, 11008]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.26.input_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.26.post_attention_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.27.self_attn.k_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.27.self_attn.o_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.27.mlp.gate_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.27.mlp.up_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.27.mlp.down_proj.weight - torch.Size([4096, 11008]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.27.input_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.27.post_attention_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.28.self_attn.q_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.28.self_attn.k_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.28.self_attn.v_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.28.self_attn.o_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.28.mlp.gate_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.28.mlp.up_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.28.mlp.down_proj.weight - torch.Size([4096, 11008]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.28.input_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.28.post_attention_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.29.self_attn.q_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.29.self_attn.k_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.29.self_attn.v_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.29.self_attn.o_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.29.mlp.gate_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.29.mlp.up_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.29.mlp.down_proj.weight - torch.Size([4096, 11008]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.29.input_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.29.post_attention_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.30.self_attn.q_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.30.self_attn.k_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.30.self_attn.v_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.30.self_attn.o_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.30.mlp.gate_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.30.mlp.up_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.30.mlp.down_proj.weight - torch.Size([4096, 11008]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.30.input_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.30.post_attention_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.31.self_attn.q_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.31.self_attn.k_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.31.self_attn.v_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.31.self_attn.o_proj.base_layer.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight - torch.Size([16, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight - torch.Size([4096, 16]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

lm_head.base_model.model.model.layers.31.mlp.gate_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.31.mlp.up_proj.weight - torch.Size([11008, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.31.mlp.down_proj.weight - torch.Size([4096, 11008]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.31.input_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.layers.31.post_attention_layernorm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.model.norm.weight - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

lm_head.base_model.model.lm_head.weight - torch.Size([32001, 4096]): 
Initialized by user-defined `init_weights` in PeftModelForCausalLM  

present_distribution.encoder.conv1.weight - torch.Size([8192, 4096, 1]): 
The value is the same before and after calling `init_weights` of Orion  

present_distribution.encoder.conv1.bias - torch.Size([8192]): 
The value is the same before and after calling `init_weights` of Orion  

present_distribution.encoder.conv2.weight - torch.Size([8192, 8192, 1]): 
The value is the same before and after calling `init_weights` of Orion  

present_distribution.encoder.conv2.bias - torch.Size([8192]): 
The value is the same before and after calling `init_weights` of Orion  

present_distribution.encoder.conv3.weight - torch.Size([2048, 8192, 1]): 
The value is the same before and after calling `init_weights` of Orion  

present_distribution.encoder.conv3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of Orion  

present_distribution.last_conv.1.weight - torch.Size([64, 2048, 1]): 
The value is the same before and after calling `init_weights` of Orion  

present_distribution.last_conv.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Orion  

future_distribution.encoder.conv1.weight - torch.Size([8216, 4108, 1]): 
The value is the same before and after calling `init_weights` of Orion  

future_distribution.encoder.conv1.bias - torch.Size([8216]): 
The value is the same before and after calling `init_weights` of Orion  

future_distribution.encoder.conv2.weight - torch.Size([8216, 8216, 1]): 
The value is the same before and after calling `init_weights` of Orion  

future_distribution.encoder.conv2.bias - torch.Size([8216]): 
The value is the same before and after calling `init_weights` of Orion  

future_distribution.encoder.conv3.weight - torch.Size([2054, 8216, 1]): 
The value is the same before and after calling `init_weights` of Orion  

future_distribution.encoder.conv3.bias - torch.Size([2054]): 
The value is the same before and after calling `init_weights` of Orion  

future_distribution.last_conv.1.weight - torch.Size([64, 2054, 1]): 
The value is the same before and after calling `init_weights` of Orion  

future_distribution.last_conv.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Orion  

predict_model.gru.weight_ih_l0 - torch.Size([3072, 32]): 
The value is the same before and after calling `init_weights` of Orion  

predict_model.gru.weight_hh_l0 - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

predict_model.gru.bias_ih_l0 - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of Orion  

predict_model.gru.bias_hh_l0 - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of Orion  

predict_model.gru.weight_ih_l1 - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

predict_model.gru.weight_hh_l1 - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

predict_model.gru.bias_ih_l1 - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of Orion  

predict_model.gru.bias_hh_l1 - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of Orion  

predict_model.gru.weight_ih_l2 - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

predict_model.gru.weight_hh_l2 - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

predict_model.gru.bias_ih_l2 - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of Orion  

predict_model.gru.bias_hh_l2 - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of Orion  

predict_model.gru.weight_ih_l3 - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

predict_model.gru.weight_hh_l3 - torch.Size([3072, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

predict_model.gru.bias_ih_l3 - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of Orion  

predict_model.gru.bias_hh_l3 - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of Orion  

predict_model.linear1.weight - torch.Size([2048, 1024]): 
The value is the same before and after calling `init_weights` of Orion  

predict_model.linear1.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of Orion  

predict_model.linear2.weight - torch.Size([4096, 2048]): 
The value is the same before and after calling `init_weights` of Orion  

predict_model.linear2.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

predict_model.linear3.weight - torch.Size([4096, 4096]): 
The value is the same before and after calling `init_weights` of Orion  

predict_model.linear3.bias - torch.Size([4096]): 
The value is the same before and after calling `init_weights` of Orion  

ego_fut_decoder.0.weight - torch.Size([8192, 8192]): 
The value is the same before and after calling `init_weights` of Orion  

ego_fut_decoder.0.bias - torch.Size([8192]): 
The value is the same before and after calling `init_weights` of Orion  

ego_fut_decoder.2.weight - torch.Size([8192, 8192]): 
The value is the same before and after calling `init_weights` of Orion  

ego_fut_decoder.2.bias - torch.Size([8192]): 
The value is the same before and after calling `init_weights` of Orion  

ego_fut_decoder.4.weight - torch.Size([12, 8192]): 
The value is the same before and after calling `init_weights` of Orion  

ego_fut_decoder.4.bias - torch.Size([12]): 
The value is the same before and after calling `init_weights` of Orion  
2025-11-02 19:57:39,857 - mmdet - INFO - Model:
Orion(
  (pts_bbox_head): OrionHead(
    (loss_cls): FocalLoss()
    (loss_bbox): L1Loss()
    (traj_branches): ModuleList(
      (0): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
        (1): ReLU()
        (2): Linear(in_features=512, out_features=512, bias=True)
        (3): ReLU()
        (4): Linear(in_features=512, out_features=12, bias=True)
      )
    )
    (traj_cls_branches): ModuleList(
      (0): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
        (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=512, out_features=512, bias=True)
        (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=512, out_features=1, bias=True)
      )
    )
    (cls_branches): ModuleList(
      (0-5): 6 x Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=256, out_features=256, bias=True)
        (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=9, bias=True)
      )
    )
    (reg_branches): ModuleList(
      (0-5): 6 x Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
    )
    (input_projection): Linear(in_features=1024, out_features=256, bias=True)
    (output_projection): Linear(in_features=256, out_features=4096, bias=True)
    (reference_points): Embedding(600, 3)
    (pseudo_reference_points): Embedding(300, 3)
    (query_embedding): Embedding(256, 256)
    (can_bus_embed): Sequential(
      (0): Linear(in_features=89, out_features=1024, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1024, out_features=4096, bias=True)
    )
    (loss_traj): L1Loss()
    (loss_traj_cls): FocalLoss()
    (loss_iou): GIoULoss()
    (transformer): PETRTemporalTransformer(
      (query_decoder): PETRTransformerDecoder(
        (_layers): ModuleList(
          (0-5): 6 x PETRTransformerDecoderLayer(
            (transformer_layers): ModuleList(
              (0): MultiHeadAttentionwDropout(
                (attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                )
                (proj_drop): Dropout(p=0.1, inplace=False)
              )
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): MultiHeadAttentionwDropout(
                (attn): FlashMHA(
                  (inner_attn): FlashAttention()
                  (out_proj): Linear(in_features=256, out_features=256, bias=True)
                )
                (proj_drop): Dropout(p=0.1, inplace=False)
              )
              (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (4): FFN(
                (_layers): Sequential(
                  (0): Linear(in_features=256, out_features=2048, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=2048, out_features=256, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
              (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
    )
    (motion_decoder): OrionTransformerDecoder(
      (_layers): ModuleList(
        (0): OrionTransformerDecoderLayer(
          (transformer_layers): ModuleList(
            (0): MultiHeadAttentionwDropout(
              (attn): FlashMHA(
                (inner_attn): FlashAttention()
                (out_proj): Linear(in_features=256, out_features=256, bias=False)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): FFN(
              (_layers): Sequential(
                (0): Linear(in_features=256, out_features=512, bias=True)
                (1): ReLU(inplace=True)
                (2): Dropout(p=0.0, inplace=False)
                (3): Linear(in_features=512, out_features=256, bias=True)
                (4): Dropout(p=0.0, inplace=False)
              )
            )
            (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (motion_mode_query): Embedding(6, 256)
    (memory_query): Embedding(16, 256)
    (scene_time_embedding): Sequential(
      (0): Linear(in_features=256, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (memory_decoder_cq): OrionTransformerDecoder(
      (_layers): ModuleList(
        (0): OrionTransformerDecoderLayer(
          (transformer_layers): ModuleList(
            (0): MultiHeadAttentionwDropout(
              (attn): FlashMHA(
                (inner_attn): FlashAttention()
                (out_proj): Linear(in_features=256, out_features=256, bias=False)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): FFN(
              (_layers): Sequential(
                (0): Linear(in_features=256, out_features=512, bias=True)
                (1): ReLU(inplace=True)
                (2): Dropout(p=0.0, inplace=False)
                (3): Linear(in_features=512, out_features=256, bias=True)
                (4): Dropout(p=0.0, inplace=False)
              )
            )
            (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (memory_decoder_mq): OrionTransformerDecoder(
      (_layers): ModuleList(
        (0): OrionTransformerDecoderLayer(
          (transformer_layers): ModuleList(
            (0): MultiHeadAttentionwDropout(
              (attn): FlashMHA(
                (inner_attn): FlashAttention()
                (out_proj): Linear(in_features=256, out_features=256, bias=False)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): FFN(
              (_layers): Sequential(
                (0): Linear(in_features=256, out_features=512, bias=True)
                (1): ReLU(inplace=True)
                (2): Dropout(p=0.0, inplace=False)
                (3): Linear(in_features=512, out_features=256, bias=True)
                (4): Dropout(p=0.0, inplace=False)
              )
            )
            (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (loss_traffic): FocalLoss()
    (tl_branches): ModuleList(
      (0-5): 6 x Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=256, out_features=256, bias=True)
        (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (query_pos): Sequential(
      (0): Linear(in_features=396, out_features=256, bias=True)
      (1): ReLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
    )
    (time_embedding): Sequential(
      (0): Linear(in_features=256, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (ego_pose_pe): MLN(
      (reduce): Sequential(
        (0): Linear(in_features=156, out_features=256, bias=True)
        (1): ReLU()
      )
      (gamma): Linear(in_features=256, out_features=256, bias=True)
      (beta): Linear(in_features=256, out_features=256, bias=True)
      (ln): LayerNorm((256,), eps=1e-05, elementwise_affine=False)
    )
  )
  (img_backbone): EVAViT(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
    )
    (rope_win): VisionRotaryEmbeddingFast()
    (rope_glb): VisionRotaryEmbeddingFast()
    (blocks): ModuleList(
      (0): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rope): VisionRotaryEmbeddingFast()
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (inner_attn_ln): Identity()
          (inner_attn): FlashAttention()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): SwiGLU(
          (w1): Linear(in_features=1024, out_features=2730, bias=True)
          (w2): Linear(in_features=1024, out_features=2730, bias=True)
          (act): SiLU()
          (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)
          (w3): Linear(in_features=2730, out_features=1024, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1-23): 23 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (rope): VisionRotaryEmbeddingFast()
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (inner_attn_ln): Identity()
          (inner_attn): FlashAttention()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): SwiGLU(
          (w1): Linear(in_features=1024, out_features=2730, bias=True)
          (w2): Linear(in_features=1024, out_features=2730, bias=True)
          (act): SiLU()
          (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)
          (w3): Linear(in_features=2730, out_features=1024, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (grid_mask): GridMask()
  (query_pos): Sequential(
    (0): Linear(in_features=396, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
  )
  (time_embedding): Sequential(
    (0): Linear(in_features=256, out_features=256, bias=True)
    (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (ego_pose_pe): MLN(
    (reduce): Sequential(
      (0): Linear(in_features=156, out_features=256, bias=True)
      (1): ReLU()
    )
    (gamma): Linear(in_features=256, out_features=256, bias=True)
    (beta): Linear(in_features=256, out_features=256, bias=True)
    (ln): LayerNorm((256,), eps=1e-05, elementwise_affine=False)
  )
  (map_head): OrionHeadM(
    (loss_cls): FocalLoss()
    (loss_bbox): L1Loss()
    (cls_branches): ModuleList(
      (0-5): 6 x Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=256, out_features=256, bias=True)
        (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=6, bias=True)
      )
    )
    (reg_branches): ModuleList(
      (0-5): 6 x Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=33, bias=True)
      )
    )
    (input_projection): Linear(in_features=1024, out_features=256, bias=True)
    (output_projection): Linear(in_features=256, out_features=4096, bias=True)
    (reference_points_lane): Linear(in_features=256, out_features=3, bias=True)
    (points_embedding_lane): Embedding(11, 256)
    (instance_embedding_lane): Embedding(1800, 256)
    (query_embedding): Embedding(256, 256)
    (loss_dir): PtsDirCosLoss()
    (transformer): PETRTemporalTransformer(
      (query_decoder): PETRTransformerDecoder(
        (_layers): ModuleList(
          (0-5): 6 x PETRTransformerDecoderLayer(
            (transformer_layers): ModuleList(
              (0): MultiHeadAttentionwDropout(
                (attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                )
                (proj_drop): Dropout(p=0.1, inplace=False)
              )
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): MultiHeadAttentionwDropout(
                (attn): FlashMHA(
                  (inner_attn): FlashAttention()
                  (out_proj): Linear(in_features=256, out_features=256, bias=True)
                )
                (proj_drop): Dropout(p=0.1, inplace=False)
              )
              (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (4): FFN(
                (_layers): Sequential(
                  (0): Linear(in_features=256, out_features=2048, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=2048, out_features=256, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
              (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
    )
    (query_pos): Sequential(
      (0): Linear(in_features=396, out_features=256, bias=True)
      (1): ReLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
    )
    (time_embedding): Sequential(
      (0): Linear(in_features=256, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (ego_pose_pe): MLN(
      (reduce): Sequential(
        (0): Linear(in_features=156, out_features=256, bias=True)
        (1): ReLU()
      )
      (gamma): Linear(in_features=256, out_features=256, bias=True)
      (beta): Linear(in_features=256, out_features=256, bias=True)
      (ln): LayerNorm((256,), eps=1e-05, elementwise_affine=False)
    )
  )
  (position_encoder): Sequential(
    (0): Linear(in_features=192, out_features=1024, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1024, out_features=256, bias=True)
  )
  (lm_head): PeftModelForCausalLM(
    (base_model): LoraModel(
      (model): LlavaLlamaForCausalLM(
        (model): LlavaLlamaModel(
          (embed_tokens): Embedding(32001, 4096)
          (layers): ModuleList(
            (0-31): 32 x LlamaDecoderLayer(
              (self_attn): LlamaAttention(
                (q_proj): lora.Linear(
                  (base_layer): Linear(in_features=4096, out_features=4096, bias=False)
                  (lora_dropout): ModuleDict(
                    (default): Dropout(p=0.05, inplace=False)
                  )
                  (lora_A): ModuleDict(
                    (default): Linear(in_features=4096, out_features=16, bias=False)
                  )
                  (lora_B): ModuleDict(
                    (default): Linear(in_features=16, out_features=4096, bias=False)
                  )
                  (lora_embedding_A): ParameterDict()
                  (lora_embedding_B): ParameterDict()
                  (lora_magnitude_vector): ModuleDict()
                )
                (k_proj): lora.Linear(
                  (base_layer): Linear(in_features=4096, out_features=4096, bias=False)
                  (lora_dropout): ModuleDict(
                    (default): Dropout(p=0.05, inplace=False)
                  )
                  (lora_A): ModuleDict(
                    (default): Linear(in_features=4096, out_features=16, bias=False)
                  )
                  (lora_B): ModuleDict(
                    (default): Linear(in_features=16, out_features=4096, bias=False)
                  )
                  (lora_embedding_A): ParameterDict()
                  (lora_embedding_B): ParameterDict()
                  (lora_magnitude_vector): ModuleDict()
                )
                (v_proj): lora.Linear(
                  (base_layer): Linear(in_features=4096, out_features=4096, bias=False)
                  (lora_dropout): ModuleDict(
                    (default): Dropout(p=0.05, inplace=False)
                  )
                  (lora_A): ModuleDict(
                    (default): Linear(in_features=4096, out_features=16, bias=False)
                  )
                  (lora_B): ModuleDict(
                    (default): Linear(in_features=16, out_features=4096, bias=False)
                  )
                  (lora_embedding_A): ParameterDict()
                  (lora_embedding_B): ParameterDict()
                  (lora_magnitude_vector): ModuleDict()
                )
                (o_proj): lora.Linear(
                  (base_layer): Linear(in_features=4096, out_features=4096, bias=False)
                  (lora_dropout): ModuleDict(
                    (default): Dropout(p=0.05, inplace=False)
                  )
                  (lora_A): ModuleDict(
                    (default): Linear(in_features=4096, out_features=16, bias=False)
                  )
                  (lora_B): ModuleDict(
                    (default): Linear(in_features=16, out_features=4096, bias=False)
                  )
                  (lora_embedding_A): ParameterDict()
                  (lora_embedding_B): ParameterDict()
                  (lora_magnitude_vector): ModuleDict()
                )
                (rotary_emb): LlamaRotaryEmbedding()
              )
              (mlp): LlamaMLP(
                (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
                (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
                (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
                (act_fn): SiLUActivation()
              )
              (input_layernorm): LlamaRMSNorm()
              (post_attention_layernorm): LlamaRMSNorm()
            )
          )
          (norm): LlamaRMSNorm()
        )
        (lm_head): Linear(in_features=4096, out_features=32001, bias=False)
      )
    )
  )
  (present_distribution): DistributionModule(
    (encoder): DistributionEncoder1DV2(
      (conv1): Conv1d(4096, 8192, kernel_size=(1,), stride=(1,))
      (conv2): Conv1d(8192, 8192, kernel_size=(1,), stride=(1,))
      (conv3): Conv1d(8192, 2048, kernel_size=(1,), stride=(1,))
      (relu): ReLU(inplace=True)
    )
    (last_conv): Sequential(
      (0): AdaptiveAvgPool1d(output_size=1)
      (1): Conv1d(2048, 64, kernel_size=(1,), stride=(1,))
    )
  )
  (future_distribution): DistributionModule(
    (encoder): DistributionEncoder1DV2(
      (conv1): Conv1d(4108, 8216, kernel_size=(1,), stride=(1,))
      (conv2): Conv1d(8216, 8216, kernel_size=(1,), stride=(1,))
      (conv3): Conv1d(8216, 2054, kernel_size=(1,), stride=(1,))
      (relu): ReLU(inplace=True)
    )
    (last_conv): Sequential(
      (0): AdaptiveAvgPool1d(output_size=1)
      (1): Conv1d(2054, 64, kernel_size=(1,), stride=(1,))
    )
  )
  (predict_model): PredictModel(
    (gru): GRU(32, 1024, num_layers=4)
    (linear1): Linear(in_features=1024, out_features=2048, bias=True)
    (linear2): Linear(in_features=2048, out_features=4096, bias=True)
    (linear3): Linear(in_features=4096, out_features=4096, bias=True)
    (relu): ReLU(inplace=True)
  )
  (ego_fut_decoder): Sequential(
    (0): Linear(in_features=8192, out_features=8192, bias=True)
    (1): ReLU()
    (2): Linear(in_features=8192, out_features=8192, bias=True)
    (3): ReLU()
    (4): Linear(in_features=8192, out_features=12, bias=True)
  )
  (loss_plan_reg): L1Loss()
  (loss_plan_bound): PlanMapBoundLoss()
  (loss_plan_col): PlanCollisionLoss()
  (loss_vae_gen): ProbabilisticLoss()
)
